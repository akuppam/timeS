{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://eng.uber.com/m4-forecasting-competition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-7a44af22f56d>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-7a44af22f56d>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    Calculates the moving averages for a given TS\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# ML_benchmarks.py\n",
    "# Changed syntax for 'def moving averages' a bit....\n",
    "# ....from.....\n",
    "\"\"\"\n",
    "def moving_averages(ts_init, window):\n",
    "    \"\"\"\n",
    "    Calculates the moving averages for a given TS\n",
    "\n",
    "    :param ts_init: the original time series\n",
    "    :param window: window length\n",
    "    :return: moving averages ts\n",
    "    \"\"\"\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "        ts_ma = pd.rolling_mean(ts_ma, 2, center=True)\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = pd.rolling_mean(ts_init, window, center=True)\n",
    "\n",
    "    return ts_ma\n",
    "\"\"\"\n",
    "##...to.....\n",
    "\"\"\"\n",
    "    ts_init = pd.Series(ts_init)\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "        ts_ma = ts_ma.rolling(2).mean()\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "\n",
    "    return ts_ma\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:255: DeprecationWarning: This function is deprecated. Please call randint(0, 100 + 1) instead\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TS ID:  1 -------------\n",
      "-------------TS ID:  2 -------------\n",
      "-------------TS ID:  3 -------------\n",
      "-------------TS ID:  4 -------------\n",
      "-------------TS ID:  5 -------------\n",
      "-------------TS ID:  6 -------------\n",
      "-------------TS ID:  7 -------------\n",
      "-------------TS ID:  8 -------------\n",
      "-------------TS ID:  9 -------------\n",
      "-------------TS ID:  10 -------------\n",
      "-------------TS ID:  11 -------------\n",
      "-------------TS ID:  12 -------------\n",
      "-------------TS ID:  13 -------------\n",
      "-------------TS ID:  14 -------------\n",
      "-------------TS ID:  15 -------------\n",
      "-------------TS ID:  16 -------------\n",
      "-------------TS ID:  17 -------------\n",
      "-------------TS ID:  18 -------------\n",
      "-------------TS ID:  19 -------------\n",
      "-------------TS ID:  20 -------------\n",
      "-------------TS ID:  21 -------------\n",
      "-------------TS ID:  22 -------------\n",
      "-------------TS ID:  23 -------------\n",
      "-------------TS ID:  24 -------------\n",
      "-------------TS ID:  25 -------------\n",
      "-------------TS ID:  26 -------------\n",
      "-------------TS ID:  27 -------------\n",
      "-------------TS ID:  28 -------------\n",
      "-------------TS ID:  29 -------------\n",
      "-------------TS ID:  30 -------------\n",
      "-------------TS ID:  31 -------------\n",
      "-------------TS ID:  32 -------------\n",
      "-------------TS ID:  33 -------------\n",
      "-------------TS ID:  34 -------------\n",
      "-------------TS ID:  35 -------------\n",
      "-------------TS ID:  36 -------------\n",
      "-------------TS ID:  37 -------------\n",
      "-------------TS ID:  38 -------------\n",
      "-------------TS ID:  39 -------------\n",
      "-------------TS ID:  40 -------------\n",
      "-------------TS ID:  41 -------------\n",
      "-------------TS ID:  42 -------------\n",
      "-------------TS ID:  43 -------------\n",
      "-------------TS ID:  44 -------------\n",
      "-------------TS ID:  45 -------------\n",
      "-------------TS ID:  46 -------------\n",
      "-------------TS ID:  47 -------------\n",
      "-------------TS ID:  48 -------------\n",
      "-------------TS ID:  49 -------------\n",
      "-------------TS ID:  50 -------------\n",
      "-------------TS ID:  51 -------------\n",
      "-------------TS ID:  52 -------------\n",
      "-------------TS ID:  53 -------------\n",
      "-------------TS ID:  54 -------------\n",
      "-------------TS ID:  55 -------------\n",
      "-------------TS ID:  56 -------------\n",
      "-------------TS ID:  57 -------------\n",
      "-------------TS ID:  58 -------------\n",
      "-------------TS ID:  59 -------------\n",
      "-------------TS ID:  60 -------------\n",
      "-------------TS ID:  61 -------------\n",
      "-------------TS ID:  62 -------------\n",
      "-------------TS ID:  63 -------------\n",
      "-------------TS ID:  64 -------------\n",
      "-------------TS ID:  65 -------------\n",
      "-------------TS ID:  66 -------------\n",
      "-------------TS ID:  67 -------------\n",
      "-------------TS ID:  68 -------------\n",
      "-------------TS ID:  69 -------------\n",
      "-------------TS ID:  70 -------------\n",
      "-------------TS ID:  71 -------------\n",
      "-------------TS ID:  72 -------------\n",
      "-------------TS ID:  73 -------------\n",
      "-------------TS ID:  74 -------------\n",
      "-------------TS ID:  75 -------------\n",
      "-------------TS ID:  76 -------------\n",
      "-------------TS ID:  77 -------------\n",
      "-------------TS ID:  78 -------------\n",
      "-------------TS ID:  79 -------------\n",
      "-------------TS ID:  80 -------------\n",
      "-------------TS ID:  81 -------------\n",
      "-------------TS ID:  82 -------------\n",
      "-------------TS ID:  83 -------------\n",
      "-------------TS ID:  84 -------------\n",
      "-------------TS ID:  85 -------------\n",
      "-------------TS ID:  86 -------------\n",
      "-------------TS ID:  87 -------------\n",
      "-------------TS ID:  88 -------------\n",
      "-------------TS ID:  89 -------------\n",
      "-------------TS ID:  90 -------------\n",
      "-------------TS ID:  91 -------------\n",
      "-------------TS ID:  92 -------------\n",
      "-------------TS ID:  93 -------------\n",
      "-------------TS ID:  94 -------------\n",
      "-------------TS ID:  95 -------------\n",
      "-------------TS ID:  96 -------------\n",
      "-------------TS ID:  97 -------------\n",
      "-------------TS ID:  98 -------------\n",
      "-------------TS ID:  99 -------------\n",
      "-------------TS ID:  100 -------------\n",
      "\n",
      "\n",
      "---------FINAL RESULTS---------\n",
      "=============sMAPE=============\n",
      "\n",
      "#### MLP ####\n",
      " 0.2858025132447297 \n",
      "\n",
      "#### RNN ####\n",
      " 0.28997352585196495 \n",
      "\n",
      "==============MASE=============\n",
      "#### MLP ####\n",
      " 2.0304538296468215 \n",
      "\n",
      "#### RNN ####\n",
      " 2.0923073 \n",
      "\n",
      "[[ 63.  53.  72.]\n",
      " [ 53.  72.  53.]\n",
      " [ 72.  53.  99.]\n",
      " [ 53.  99.  52.]\n",
      " [ 99.  52.  79.]\n",
      " [ 52.  79. 115.]\n",
      " [ 79. 115.  94.]\n",
      " [115.  94. 114.]\n",
      " [ 94. 114. 193.]\n",
      " [114. 193. 187.]\n",
      " [193. 187. 190.]]\n",
      "[[187. 190. 146.]]\n",
      "[ 53.  99.  52.  79. 115.  94. 114. 193. 187. 190. 146.]\n",
      "[223. 249. 168. 207. 227. 249.]\n",
      "[[ 51.        102.         34.        ... 257.        209.\n",
      "  227.       ]\n",
      " [  1.0000013  73.         79.        ... 231.        241.\n",
      "  236.       ]\n",
      " [ 61.         60.         74.        ... 259.        232.\n",
      "  191.       ]\n",
      " ...\n",
      " [ 46.         89.        120.        ... 233.        204.\n",
      "  213.       ]\n",
      " [ 11.         27.         34.        ... 240.        182.\n",
      "  282.       ]\n",
      " [ 63.         53.         72.        ... 207.        227.\n",
      "  249.       ]]\n"
     ]
    }
   ],
   "source": [
    "# This code can be used to reproduce the forecasts of M4 Competition NN benchmarks and evaluate their accuracy\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import backend as ker\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "\n",
    "def detrend(insample_data):\n",
    "    \"\"\"\n",
    "    Calculates a & b parameters of LRL\n",
    "\n",
    "    :param insample_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.arange(len(insample_data))\n",
    "    a, b = np.polyfit(x, insample_data, 1)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def deseasonalize(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Calculates and returns seasonal indices\n",
    "\n",
    "    :param original_ts: original data\n",
    "    :param ppy: periods per year\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # === get in-sample data\n",
    "    original_ts = original_ts[:-out_of_sample]\n",
    "    \"\"\"\n",
    "    if seasonality_test(original_ts, ppy):\n",
    "        # print(\"seasonal\")\n",
    "        # ==== get moving averages\n",
    "        ma_ts = moving_averages(original_ts, ppy)\n",
    "\n",
    "        # ==== get seasonality indices\n",
    "        le_ts = original_ts * 100 / ma_ts\n",
    "        le_ts = np.hstack((le_ts, np.full((ppy - (len(le_ts) % ppy)), np.nan)))\n",
    "        le_ts = np.reshape(le_ts, (-1, ppy))\n",
    "        si = np.nanmean(le_ts, 0)\n",
    "        norm = np.sum(si) / (ppy * 100)\n",
    "        si = si / norm\n",
    "    else:\n",
    "        # print(\"NOT seasonal\")\n",
    "        si = np.full(ppy, 100)\n",
    "\n",
    "    return si\n",
    "\n",
    "\n",
    "def moving_averages(ts_init, window):\n",
    "    \"\"\"\n",
    "    Calculates the moving averages for a given TS\n",
    "\n",
    "    :param ts_init: the original time series\n",
    "    :param window: window length\n",
    "    :return: moving averages ts\n",
    "    \"\"\"\n",
    "    ts_init = pd.Series(ts_init)\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "        ts_ma = ts_ma.rolling(2).mean()\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "\n",
    "    return ts_ma\n",
    "\n",
    "def seasonality_test(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Seasonality test\n",
    "\n",
    "    :param original_ts: time series\n",
    "    :param ppy: periods per year\n",
    "    :return: boolean value: whether the TS is seasonal\n",
    "    \"\"\"\n",
    "    s = acf(original_ts, 1)\n",
    "    for i in range(2, ppy):\n",
    "        s = s + (acf(original_ts, i) ** 2)\n",
    "\n",
    "    limit = 1.645 * (sqrt((1 + 2 * s) / len(original_ts)))\n",
    "\n",
    "    return (abs(acf(original_ts, ppy))) > limit\n",
    "\n",
    "\n",
    "def acf(data, k):\n",
    "    \"\"\"\n",
    "    Autocorrelation function\n",
    "\n",
    "    :param data: time series\n",
    "    :param k: lag\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = np.mean(data)\n",
    "    s1 = 0\n",
    "    for i in range(k, len(data)):\n",
    "        s1 = s1 + ((data[i] - m) * (data[i - k] - m))\n",
    "\n",
    "    s2 = 0\n",
    "    for i in range(0, len(data)):\n",
    "        s2 = s2 + ((data[i] - m) ** 2)\n",
    "\n",
    "    return float(s1 / s2)\n",
    "\n",
    "\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num):]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def rnn_bench(x_train, y_train, x_test, fh, input_size):\n",
    "    \"\"\"\n",
    "    Forecasts using 6 SimpleRNN nodes in the hidden layer and a Dense output layer\n",
    "\n",
    "    :param x_train: train data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :param input_size: number of points used as input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "    x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential([\n",
    "        SimpleRNN(6, input_shape=(input_size, 1), activation='linear',\n",
    "                  use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                  dropout=0.0, recurrent_dropout=0.0),\n",
    "        Dense(1, use_bias=True, activation='linear')\n",
    "    ])\n",
    "    opt = rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def mlp_bench(x_train, y_train, x_test, fh):\n",
    "    \"\"\"\n",
    "    Forecasts using a simple MLP which 6 nodes in the hidden layer\n",
    "\n",
    "    :param x_train: train input data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_test = []\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=6, activation='identity', solver='adam',\n",
    "                         max_iter=100, learning_rate='adaptive', learning_rate_init=0.001,\n",
    "                         random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def smape(a, b):\n",
    "    \"\"\"\n",
    "    Calculates sMAPE\n",
    "\n",
    "    :param a: actual values\n",
    "    :param b: predicted values\n",
    "    :return: sMAPE\n",
    "    \"\"\"\n",
    "    a = np.reshape(a, (-1,))\n",
    "    b = np.reshape(b, (-1,))\n",
    "    return np.mean(2.0 * np.abs(a - b) / (np.abs(a) + np.abs(b))).item()\n",
    "\n",
    "\n",
    "def mase(insample, y_test, y_hat_test, freq):\n",
    "    \"\"\"\n",
    "    Calculates MAsE\n",
    "\n",
    "    :param insample: insample data\n",
    "    :param y_test: out of sample target values\n",
    "    :param y_hat_test: predicted values\n",
    "    :param freq: data frequency\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_naive = []\n",
    "    for i in range(freq, len(insample)):\n",
    "        y_hat_naive.append(insample[(i - freq)])\n",
    "\n",
    "    masep = np.mean(abs(insample[freq:] - y_hat_naive))\n",
    "\n",
    "    return np.mean(abs(y_test - y_hat_test)) / masep\n",
    "\n",
    "\n",
    "def main():\n",
    "    fh = 6         # forecasting horizon\n",
    "    freq = 1       # data frequency\n",
    "    in_size = 3    # number of points used as input for each forecast\n",
    "\n",
    "    err_MLP_sMAPE = []\n",
    "    err_MLP_MASE = []\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "\n",
    "    # ===== In this example we produce forecasts for 100 randomly generated timeseries =====\n",
    "    data_all = np.array(np.random.random_integers(0, 100, (100, 20)), dtype=np.float32)\n",
    "    for i in range(0, 100):\n",
    "        for j in range(0, 20):\n",
    "            data_all[i, j] = j * 10 + data_all[i, j]\n",
    "\n",
    "    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        ts = data_all[j, :]\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # RNN benchmark - Produce forecasts\n",
    "        y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "\n",
    "        # MLP benchmark - Produce forecasts\n",
    "        y_hat_test_MLP = mlp_bench(x_train, y_train, x_test, fh)\n",
    "        for i in range(0, 29):\n",
    "            y_hat_test_MLP = np.vstack((y_hat_test_MLP, mlp_bench(x_train, y_train, x_test, fh)))\n",
    "        y_hat_test_MLP = np.median(y_hat_test_MLP, axis=0)\n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_MLP[i - len(ts)] = y_hat_test_MLP[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_MLP)):\n",
    "            if y_hat_test_MLP[i] < 0:\n",
    "                y_hat_test_MLP[i] = 0\n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            if y_hat_test_MLP[i] > (1000 * max(ts)):\n",
    "                y_hat_test_MLP[i] = max(ts)         \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # Calculate errors\n",
    "        err_MLP_sMAPE.append(smape(y_test, y_hat_test_MLP))\n",
    "        err_RNN_sMAPE.append(smape(y_test, y_hat_test_RNN))\n",
    "        err_MLP_MASE.append(mase(ts[:-fh], y_test, y_hat_test_MLP, freq))\n",
    "        err_RNN_MASE.append(mase(ts[:-fh], y_test, y_hat_test_RNN, freq))\n",
    "\n",
    "        # memory handling\n",
    "        ker.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "        counter = counter + 1\n",
    "        print(\"-------------TS ID: \", counter, \"-------------\")\n",
    "\n",
    "    print(\"\\n\\n---------FINAL RESULTS---------\")\n",
    "    print(\"=============sMAPE=============\\n\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_sMAPE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_sMAPE), \"\\n\")\n",
    "    print(\"==============MASE=============\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_MASE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_MASE), \"\\n\")\n",
    "    print(x_train)\n",
    "    print(x_test)\n",
    "    print(y_train)\n",
    "    print(y_test)\n",
    "    print(data_all)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-80784060c951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f17ce15bebd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_all' is not defined"
     ]
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 100 + 1) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all = np.array(np.random.random_integers(0, 100, (100, 20)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 5 + 1) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all = np.array(np.random.random_integers(0, 5, (5, 3)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 1., 1.],\n",
       "       [2., 5., 3.],\n",
       "       [5., 0., 4.],\n",
       "       [4., 1., 2.],\n",
       "       [2., 4., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 100 + 1) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all = np.array(np.random.random_integers(0, 100, (100, 20)), dtype=np.float32)\n",
    "for i in range(0, 100):\n",
    "    for j in range(0, 20):\n",
    "        data_all[i, j] = j * 10 + data_all[i, j]\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71.,  93.,  57., ..., 225., 218., 259.],\n",
       "       [ 82.,  67.,  42., ..., 184., 181., 250.],\n",
       "       [ 58.,  26.,  30., ..., 217., 274., 242.],\n",
       "       ...,\n",
       "       [ 85.,  49.,  48., ..., 181., 280., 277.],\n",
       "       [ 48., 106., 100., ..., 268., 189., 197.],\n",
       "       [ 17.,  26.,  88., ..., 205., 234., 226.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(data_all)):\n",
    "    ts = data_all[j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.,  26.,  88.,  59., 134.,  88., 120.,  93., 160., 187., 134.,\n",
       "       188., 180., 204., 237., 221., 174., 205., 234., 226.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>marketing</th>\n",
       "      <th>visits</th>\n",
       "      <th>br</th>\n",
       "      <th>inq</th>\n",
       "      <th>gb</th>\n",
       "      <th>cb</th>\n",
       "      <th>nb</th>\n",
       "      <th>ss</th>\n",
       "      <th>ts</th>\n",
       "      <th>listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>2293712</td>\n",
       "      <td>8845</td>\n",
       "      <td>118349</td>\n",
       "      <td>8205</td>\n",
       "      <td>698</td>\n",
       "      <td>7507</td>\n",
       "      <td>6.740627e+05</td>\n",
       "      <td>191935.4706</td>\n",
       "      <td>28296771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>2620436</td>\n",
       "      <td>10255</td>\n",
       "      <td>142797</td>\n",
       "      <td>10094</td>\n",
       "      <td>838</td>\n",
       "      <td>9256</td>\n",
       "      <td>7.939500e+05</td>\n",
       "      <td>248524.9014</td>\n",
       "      <td>28205540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3186849</td>\n",
       "      <td>12837</td>\n",
       "      <td>184483</td>\n",
       "      <td>12351</td>\n",
       "      <td>890</td>\n",
       "      <td>11461</td>\n",
       "      <td>7.694853e+05</td>\n",
       "      <td>299503.2650</td>\n",
       "      <td>28194192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3317763</td>\n",
       "      <td>13517</td>\n",
       "      <td>188283</td>\n",
       "      <td>14251</td>\n",
       "      <td>1415</td>\n",
       "      <td>12836</td>\n",
       "      <td>1.711552e+06</td>\n",
       "      <td>339585.2933</td>\n",
       "      <td>28349902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3267402</td>\n",
       "      <td>14318</td>\n",
       "      <td>194315</td>\n",
       "      <td>15468</td>\n",
       "      <td>1584</td>\n",
       "      <td>13884</td>\n",
       "      <td>1.814768e+06</td>\n",
       "      <td>368632.8372</td>\n",
       "      <td>28373795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date region marketing   visits     br     inq     gb    cb     nb  \\\n",
       "0  2016-01-01    all       all  2293712   8845  118349   8205   698   7507   \n",
       "1  2016-01-02    all       all  2620436  10255  142797  10094   838   9256   \n",
       "2  2016-01-03    all       all  3186849  12837  184483  12351   890  11461   \n",
       "3  2016-01-04    all       all  3317763  13517  188283  14251  1415  12836   \n",
       "4  2016-01-05    all       all  3267402  14318  194315  15468  1584  13884   \n",
       "\n",
       "             ss           ts  listings  \n",
       "0  6.740627e+05  191935.4706  28296771  \n",
       "1  7.939500e+05  248524.9014  28205540  \n",
       "2  7.694853e+05  299503.2650  28194192  \n",
       "3  1.711552e+06  339585.2933  28349902  \n",
       "4  1.814768e+06  368632.8372  28373795  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"/users/akuppam/documents/Data/RoverData/rnbl2agg.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a299697d32f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_into_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-2d91ec4a7aa9>\u001b[0m in \u001b[0;36msplit_into_train_test\u001b[0;34m(data, in_num, fh)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtemp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \"\"\"\n\u001b[1;32m    646\u001b[0m         return self._constructor(result, index=self.index,\n\u001b[0;32m--> 647\u001b[0;31m                                  copy=False).__finalize__(self)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_prepare__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 274\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   4159\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4161\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4163\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "fh = 120\n",
    "freq = 12\n",
    "in_size = 3\n",
    "\n",
    "ts = df['nb']\n",
    "\n",
    "# remove seasonality\n",
    "seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "for i in range(0, len(ts)):\n",
    "    ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "# detrending\n",
    "a, b = detrend(ts)\n",
    "\n",
    "for i in range(0, len(ts)):\n",
    "    ts[i] = ts[i] - ((a * i) + b)\n",
    "    \n",
    "x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 120\n",
    "freq = 24\n",
    "in_size = 3\n",
    "\n",
    "ts = df['nb']\n",
    "\n",
    "# remove seasonality\n",
    "seasonality_in = deseasonalize(ts, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99.99621861, 100.91995481,  99.63610957,  98.50173886,\n",
       "        98.29649125,  97.78634866,  99.76520205, 100.76620963,\n",
       "       100.68059728, 100.66266576,  99.90091396, 101.43417348,\n",
       "       101.76111885, 101.17292855, 101.47018262, 100.52818236,\n",
       "       100.97469613,  99.78564245, 100.02676321,  99.37224527,\n",
       "        99.22621666, 100.49696666,  97.6339714 ,  99.2044619 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonality_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seasonality_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2aef2eac61d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mseasonality_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# detrending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetrend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seasonality_in' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(ts)):\n",
    "    ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "# detrending\n",
    "a, b = detrend(ts)\n",
    "\n",
    "for i in range(0, len(ts)):\n",
    "    ts[i] = ts[i] - ((a * i) + b)\n",
    "    \n",
    "x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d7699a195dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d7699a195dfe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# ===== Main loop which goes through all timeseries =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# remove seasonality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    fh = 120         # forecasting horizon\n",
    "    freq = 12       # data frequency\n",
    "    in_size = 3    # number of points used as input for each forecast\n",
    "\n",
    "    err_MLP_sMAPE = []\n",
    "    err_MLP_MASE = []\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "\n",
    "    # ===== In this example we produce forecasts for 100 randomly generated timeseries =====\n",
    "    data_all = df['nb']\n",
    "#    for i in range(0, 100):\n",
    "#        for j in range(0, 20):\n",
    "#            data_all[i, j] = j * 10 + data_all[i, j]\n",
    "\n",
    "#    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        ts = data_all[j, :]\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 100 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # RNN benchmark - Produce forecasts\n",
    "        y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "\n",
    "        # MLP benchmark - Produce forecasts\n",
    "        y_hat_test_MLP = mlp_bench(x_train, y_train, x_test, fh)\n",
    "        for i in range(0, 29):\n",
    "            y_hat_test_MLP = np.vstack((y_hat_test_MLP, mlp_bench(x_train, y_train, x_test, fh)))\n",
    "        y_hat_test_MLP = np.median(y_hat_test_MLP, axis=0)\n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_MLP[i - len(ts)] = y_hat_test_MLP[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 100\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_MLP)):\n",
    "            if y_hat_test_MLP[i] < 0:\n",
    "                y_hat_test_MLP[i] = 0\n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            if y_hat_test_MLP[i] > (1000 * max(ts)):\n",
    "                y_hat_test_MLP[i] = max(ts)         \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # Calculate errors\n",
    "        err_MLP_sMAPE.append(smape(y_test, y_hat_test_MLP))\n",
    "        err_RNN_sMAPE.append(smape(y_test, y_hat_test_RNN))\n",
    "        err_MLP_MASE.append(mase(ts[:-fh], y_test, y_hat_test_MLP, freq))\n",
    "        err_RNN_MASE.append(mase(ts[:-fh], y_test, y_hat_test_RNN, freq))\n",
    "\n",
    "        # memory handling\n",
    "        ker.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "        counter = counter + 1\n",
    "        print(\"-------------TS ID: \", counter, \"-------------\")\n",
    "\n",
    "    print(\"\\n\\n---------FINAL RESULTS---------\")\n",
    "    print(\"=============sMAPE=============\\n\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_sMAPE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_sMAPE), \"\\n\")\n",
    "    print(\"==============MASE=============\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_MASE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_MASE), \"\\n\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'rolling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-01fb62979e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'rolling'"
     ]
    }
   ],
   "source": [
    "b.rolling(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.Series(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.5\n",
       "2    2.5\n",
       "3    3.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.rolling(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.5\n",
       "2    2.5\n",
       "3    3.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.rolling(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> s = pd.Series([1, 2, 3, 4])\n",
    ">>> s.rolling(2).mean()\n",
    "0    NaN\n",
    "1    1.5\n",
    "2    2.5\n",
    "3    3.5\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:255: DeprecationWarning: This function is deprecated. Please call randint(0, 5 + 1) instead\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4970687a237c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-4970687a237c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# RNN benchmark - Produce forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0my_hat_test_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_bench\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# MLP benchmark - Produce forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4970687a237c>\u001b[0m in \u001b[0;36mrnn_bench\u001b[0;34m(x_train, y_train, x_test, fh, input_size)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mlast_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0my_hat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# This code can be used to reproduce the forecasts of M4 Competition NN benchmarks and evaluate their accuracy\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.optimizers import rmsprop\n",
    "from keras import backend as ker\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "\n",
    "def detrend(insample_data):\n",
    "    \"\"\"\n",
    "    Calculates a & b parameters of LRL\n",
    "\n",
    "    :param insample_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = np.arange(len(insample_data))\n",
    "    a, b = np.polyfit(x, insample_data, 1)\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def deseasonalize(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Calculates and returns seasonal indices\n",
    "\n",
    "    :param original_ts: original data\n",
    "    :param ppy: periods per year\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # === get in-sample data\n",
    "    original_ts = original_ts[:-out_of_sample]\n",
    "    \"\"\"\n",
    "    if seasonality_test(original_ts, ppy):\n",
    "        # print(\"seasonal\")\n",
    "        # ==== get moving averages\n",
    "        ma_ts = moving_averages(original_ts, ppy)\n",
    "\n",
    "        # ==== get seasonality indices\n",
    "        le_ts = original_ts * 5 / ma_ts\n",
    "        le_ts = np.hstack((le_ts, np.full((ppy - (len(le_ts) % ppy)), np.nan)))\n",
    "        le_ts = np.reshape(le_ts, (-1, ppy))\n",
    "        si = np.nanmean(le_ts, 0)\n",
    "        norm = np.sum(si) / (ppy * 5)\n",
    "        si = si / norm\n",
    "    else:\n",
    "        # print(\"NOT seasonal\")\n",
    "        si = np.full(ppy, 5)\n",
    "\n",
    "    return si\n",
    "\n",
    "\n",
    "def moving_averages(ts_init, window):\n",
    "    \"\"\"\n",
    "    Calculates the moving averages for a given TS\n",
    "\n",
    "    :param ts_init: the original time series\n",
    "    :param window: window length\n",
    "    :return: moving averages ts\n",
    "    \"\"\"\n",
    "    ts_init = pd.Series(ts_init)\n",
    "    if len(ts_init) % 2 == 0:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "        ts_ma = ts_ma.rolling(2).mean()\n",
    "        ts_ma = np.roll(ts_ma, -1)\n",
    "    else:\n",
    "        ts_ma = ts_init.rolling(window).mean()\n",
    "\n",
    "    return ts_ma\n",
    "\n",
    "def seasonality_test(original_ts, ppy):\n",
    "    \"\"\"\n",
    "    Seasonality test\n",
    "\n",
    "    :param original_ts: time series\n",
    "    :param ppy: periods per year\n",
    "    :return: boolean value: whether the TS is seasonal\n",
    "    \"\"\"\n",
    "    s = acf(original_ts, 1)\n",
    "    for i in range(2, ppy):\n",
    "        s = s + (acf(original_ts, i) ** 2)\n",
    "\n",
    "    limit = 1.645 * (sqrt((1 + 2 * s) / len(original_ts)))\n",
    "\n",
    "    return (abs(acf(original_ts, ppy))) > limit\n",
    "\n",
    "\n",
    "def acf(data, k):\n",
    "    \"\"\"\n",
    "    Autocorrelation function\n",
    "\n",
    "    :param data: time series\n",
    "    :param k: lag\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = np.mean(data)\n",
    "    s1 = 0\n",
    "    for i in range(k, len(data)):\n",
    "        s1 = s1 + ((data[i] - m) * (data[i - k] - m))\n",
    "\n",
    "    s2 = 0\n",
    "    for i in range(0, len(data)):\n",
    "        s2 = s2 + ((data[i] - m) ** 2)\n",
    "\n",
    "    return float(s1 / s2)\n",
    "\n",
    "\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num):]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def rnn_bench(x_train, y_train, x_test, fh, input_size):\n",
    "    \"\"\"\n",
    "    Forecasts using 6 SimpleRNN nodes in the hidden layer and a Dense output layer\n",
    "\n",
    "    :param x_train: train data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :param input_size: number of points used as input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "    x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential([\n",
    "        SimpleRNN(6, input_shape=(input_size, 1), activation='linear',\n",
    "                  use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                  dropout=0.0, recurrent_dropout=0.0),\n",
    "        Dense(1, use_bias=True, activation='linear')\n",
    "    ])\n",
    "    opt = rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def mlp_bench(x_train, y_train, x_test, fh):\n",
    "    \"\"\"\n",
    "    Forecasts using a simple MLP which 6 nodes in the hidden layer\n",
    "\n",
    "    :param x_train: train input data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_test = []\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=6, activation='identity', solver='adam',\n",
    "                         max_iter=100, learning_rate='adaptive', learning_rate_init=0.001,\n",
    "                         random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n",
    "\n",
    "def smape(a, b):\n",
    "    \"\"\"\n",
    "    Calculates sMAPE\n",
    "\n",
    "    :param a: actual values\n",
    "    :param b: predicted values\n",
    "    :return: sMAPE\n",
    "    \"\"\"\n",
    "    a = np.reshape(a, (-1,))\n",
    "    b = np.reshape(b, (-1,))\n",
    "    return np.mean(2.0 * np.abs(a - b) / (np.abs(a) + np.abs(b))).item()\n",
    "\n",
    "\n",
    "def mase(insample, y_test, y_hat_test, freq):\n",
    "    \"\"\"\n",
    "    Calculates MAsE\n",
    "\n",
    "    :param insample: insample data\n",
    "    :param y_test: out of sample target values\n",
    "    :param y_hat_test: predicted values\n",
    "    :param freq: data frequency\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat_naive = []\n",
    "    for i in range(freq, len(insample)):\n",
    "        y_hat_naive.append(insample[(i - freq)])\n",
    "\n",
    "    masep = np.mean(abs(insample[freq:] - y_hat_naive))\n",
    "\n",
    "    return np.mean(abs(y_test - y_hat_test)) / masep\n",
    "\n",
    "\n",
    "def main():\n",
    "    fh = 6         # forecasting horizon\n",
    "    freq = 1       # data frequency\n",
    "    in_size = 3    # number of points used as input for each forecast\n",
    "\n",
    "    err_MLP_sMAPE = []\n",
    "    err_MLP_MASE = []\n",
    "    err_RNN_sMAPE = []\n",
    "    err_RNN_MASE = []\n",
    "\n",
    "    # ===== In this example we produce forecasts for 100 randomly generated timeseries =====\n",
    "    data_all = np.array(np.random.random_integers(0, 5, (5, 2)), dtype=np.float32)\n",
    "    for i in range(0, 5):\n",
    "        for j in range(0, 2):\n",
    "            data_all[i, j] = j * 10 + data_all[i, j]\n",
    "\n",
    "    counter = 0\n",
    "    # ===== Main loop which goes through all timeseries =====\n",
    "    for j in range(len(data_all)):\n",
    "        ts = data_all[j, :]\n",
    "\n",
    "        # remove seasonality\n",
    "        seasonality_in = deseasonalize(ts, freq)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * 5 / seasonality_in[i % freq]\n",
    "\n",
    "        # detrending\n",
    "        a, b = detrend(ts)\n",
    "\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] - ((a * i) + b)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # RNN benchmark - Produce forecasts\n",
    "        y_hat_test_RNN = np.reshape(rnn_bench(x_train, y_train, x_test, fh, in_size), (-1))\n",
    "\n",
    "        # MLP benchmark - Produce forecasts\n",
    "        y_hat_test_MLP = mlp_bench(x_train, y_train, x_test, fh)\n",
    "        for i in range(0, 29):\n",
    "            y_hat_test_MLP = np.vstack((y_hat_test_MLP, mlp_bench(x_train, y_train, x_test, fh)))\n",
    "        y_hat_test_MLP = np.median(y_hat_test_MLP, axis=0)\n",
    "\n",
    "        # add trend\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] + ((a * i) + b)\n",
    "\n",
    "        for i in range(0, fh):\n",
    "            y_hat_test_MLP[i] = y_hat_test_MLP[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "            y_hat_test_RNN[i] = y_hat_test_RNN[i] + ((a * (len(ts) + i + 1)) + b)\n",
    "\n",
    "        # add seasonality\n",
    "        for i in range(0, len(ts)):\n",
    "            ts[i] = ts[i] * seasonality_in[i % freq] / 5\n",
    "\n",
    "        for i in range(len(ts), len(ts) + fh):\n",
    "            y_hat_test_MLP[i - len(ts)] = y_hat_test_MLP[i - len(ts)] * seasonality_in[i % freq] / 5\n",
    "            y_hat_test_RNN[i - len(ts)] = y_hat_test_RNN[i - len(ts)] * seasonality_in[i % freq] / 5\n",
    "\n",
    "        # check if negative or extreme\n",
    "        for i in range(len(y_hat_test_MLP)):\n",
    "            if y_hat_test_MLP[i] < 0:\n",
    "                y_hat_test_MLP[i] = 0\n",
    "            if y_hat_test_RNN[i] < 0:\n",
    "                y_hat_test_RNN[i] = 0\n",
    "                \n",
    "            if y_hat_test_MLP[i] > (1000 * max(ts)):\n",
    "                y_hat_test_MLP[i] = max(ts)         \n",
    "            if y_hat_test_RNN[i] > (1000 * max(ts)):\n",
    "                y_hat_test_RNN[i] = max(ts)\n",
    "\n",
    "        x_train, y_train, x_test, y_test = split_into_train_test(ts, in_size, fh)\n",
    "\n",
    "        # Calculate errors\n",
    "        err_MLP_sMAPE.append(smape(y_test, y_hat_test_MLP))\n",
    "        err_RNN_sMAPE.append(smape(y_test, y_hat_test_RNN))\n",
    "        err_MLP_MASE.append(mase(ts[:-fh], y_test, y_hat_test_MLP, freq))\n",
    "        err_RNN_MASE.append(mase(ts[:-fh], y_test, y_hat_test_RNN, freq))\n",
    "\n",
    "        # memory handling\n",
    "        ker.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "        counter = counter + 1\n",
    "        print(\"-------------TS ID: \", counter, \"-------------\")\n",
    "\n",
    "    print(\"\\n\\n---------FINAL RESULTS---------\")\n",
    "    print(\"=============sMAPE=============\\n\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_sMAPE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_sMAPE), \"\\n\")\n",
    "    print(\"==============MASE=============\")\n",
    "    print(\"#### MLP ####\\n\", np.mean(err_MLP_MASE), \"\\n\")\n",
    "    print(\"#### RNN ####\\n\", np.mean(err_RNN_MASE), \"\\n\")\n",
    "    print(x_train)\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_bench(x_train, y_train, x_test, fh, input_size):\n",
    "    \"\"\"\n",
    "    Forecasts using 6 SimpleRNN nodes in the hidden layer and a Dense output layer\n",
    "\n",
    "    :param x_train: train data\n",
    "    :param y_train: target values for training\n",
    "    :param x_test: test data\n",
    "    :param fh: forecasting horizon\n",
    "    :param input_size: number of points used as input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # reshape to match expected input\n",
    "    x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "    x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential([\n",
    "        SimpleRNN(6, input_shape=(input_size, 1), activation='linear',\n",
    "                  use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "                  dropout=0.0, recurrent_dropout=0.0),\n",
    "        Dense(1, use_bias=True, activation='linear')\n",
    "    ])\n",
    "    opt = rmsprop(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "    # make predictions\n",
    "    y_hat_test = []\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "    for i in range(0, fh):\n",
    "        y_hat_test.append(last_prediction)\n",
    "        x_test[0] = np.roll(x_test[0], -1)\n",
    "        x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "        last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "    return np.asarray(y_hat_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 6         # forecasting horizon\n",
    "freq = 1       # data frequency\n",
    "in_size = 3    # number of points used as input for each forecast\n",
    "#input_size = 790\n",
    "\n",
    "train = df.loc[:789]   # train on 2016/01/01 to 2018/03/31\n",
    "test = df.loc[790:]    # test on 2018/04/01 to 2018/09/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>marketing</th>\n",
       "      <th>visits</th>\n",
       "      <th>br</th>\n",
       "      <th>inq</th>\n",
       "      <th>gb</th>\n",
       "      <th>cb</th>\n",
       "      <th>nb</th>\n",
       "      <th>ss</th>\n",
       "      <th>ts</th>\n",
       "      <th>listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>2293712</td>\n",
       "      <td>8845</td>\n",
       "      <td>118349</td>\n",
       "      <td>8205</td>\n",
       "      <td>698</td>\n",
       "      <td>7507</td>\n",
       "      <td>674062.7020</td>\n",
       "      <td>191935.4706</td>\n",
       "      <td>28296771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>2620436</td>\n",
       "      <td>10255</td>\n",
       "      <td>142797</td>\n",
       "      <td>10094</td>\n",
       "      <td>838</td>\n",
       "      <td>9256</td>\n",
       "      <td>793950.0007</td>\n",
       "      <td>248524.9014</td>\n",
       "      <td>28205540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date region marketing   visits     br     inq     gb   cb    nb  \\\n",
       "0  2016-01-01    all       all  2293712   8845  118349   8205  698  7507   \n",
       "1  2016-01-02    all       all  2620436  10255  142797  10094  838  9256   \n",
       "\n",
       "            ss           ts  listings  \n",
       "0  674062.7020  191935.4706  28296771  \n",
       "1  793950.0007  248524.9014  28205540  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = train[[\"nb\",\"br\"]]\n",
    "#df1 = df[['a','b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[[\"nb\"]]\n",
    "x_train = train[[\"br\"]]\n",
    "y_test = test[[\"nb\"]]\n",
    "x_test = test[[\"br\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-221d73b9e307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#x_test = np.reshape(x_test.shape[0], 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   1605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 379\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_prep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m   7405\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7406\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must pass 2-d input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7409\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "#x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "#x_train = np.reshape(x_train.shape[0], 3)\n",
    "#x_test = np.reshape(x_test.shape[0], 3)\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "x_test = np.reshape(x_test, (-1, input_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected simple_rnn_5_input to have 3 dimensions, but got array with shape (790, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8d5cf414f02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# fit the model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected simple_rnn_5_input to have 3 dimensions, but got array with shape (790, 1)"
     ]
    }
   ],
   "source": [
    "# reshape to match expected input\n",
    "#x_train = np.reshape(x_train, (-1, input_size, 1))\n",
    "#x_test = np.reshape(x_test, (-1, input_size, 1))\n",
    "\n",
    "# create the model\n",
    "model = Sequential([\n",
    "    SimpleRNN(6, input_shape=(in_size, 1), activation='linear',\n",
    "              use_bias=False, kernel_initializer='glorot_uniform',\n",
    "              recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "              dropout=0.0, recurrent_dropout=0.0),\n",
    "    Dense(1, use_bias=True, activation='linear')\n",
    "])\n",
    "\n",
    "opt = rmsprop(lr=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "# make predictions\n",
    "y_hat_test = []\n",
    "last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "for i in range(0, fh):\n",
    "    y_hat_test.append(last_prediction)\n",
    "    x_test[0] = np.roll(x_test[0], -1)\n",
    "    x_test[0, (len(x_test[0]) - 1)] = last_prediction\n",
    "    last_prediction = model.predict(x_test)[0]\n",
    "\n",
    "return np.asarray(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
