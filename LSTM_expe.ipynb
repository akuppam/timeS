{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Market Prediction by Recurrent Neural Network on LSTM Model\n",
    "# https://medium.com/@aniruddha.choudhury94/stock-market-prediction-by-recurrent-neural-network-on-lstm-model-56de700bff68\n",
    "# Stock Market Prediction by Recurrent Neural Network on LSTM Model.PDF\n",
    "# /users/akuppam/documents/Hprog/Py/LSTM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>41.919998</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>41.320000</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>1703300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.680000</td>\n",
       "      <td>41.939999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>1285600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.700001</td>\n",
       "      <td>42.160000</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>1389900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>42.380001</td>\n",
       "      <td>42.840000</td>\n",
       "      <td>42.240002</td>\n",
       "      <td>42.740002</td>\n",
       "      <td>1523300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>42.759998</td>\n",
       "      <td>42.919998</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>42.840000</td>\n",
       "      <td>2661900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open       high        low      close     volume\n",
       "date                                                             \n",
       "2007-01-03  41.919998  42.520000  41.320000  42.099998  1703300.0\n",
       "2007-01-04  42.000000  42.680000  41.939999  42.540001  1285600.0\n",
       "2007-01-05  42.599998  42.700001  42.160000  42.520000  1389900.0\n",
       "2007-01-08  42.380001  42.840000  42.240002  42.740002  1523300.0\n",
       "2007-01-09  42.759998  42.919998  42.500000  42.840000  2661900.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('expe_train.csv',index_col=\"date\",parse_dates=True)\n",
    "dataset = dataset.drop(columns = ['Unnamed: 0', 'adjusted'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "dataset.isna().any()\n",
    "\n",
    "# Feature Scaling Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(dataset)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(dataset)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2709, 60, 1), (2709,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.20087157],\n",
       "        [0.20141632],\n",
       "        [0.20550183],\n",
       "        ...,\n",
       "        [0.23124065],\n",
       "        [0.22756367],\n",
       "        [0.22293341]],\n",
       "\n",
       "       [[0.20141632],\n",
       "        [0.20550183],\n",
       "        [0.20400382],\n",
       "        ...,\n",
       "        [0.22756367],\n",
       "        [0.22293341],\n",
       "        [0.22865314]],\n",
       "\n",
       "       [[0.20550183],\n",
       "        [0.20400382],\n",
       "        [0.2065913 ],\n",
       "        ...,\n",
       "        [0.22293341],\n",
       "        [0.22865314],\n",
       "        [0.23055971]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.89595534],\n",
       "        [0.91978756],\n",
       "        [0.91502114],\n",
       "        ...,\n",
       "        [0.73382815],\n",
       "        [0.73253439],\n",
       "        [0.73423669]],\n",
       "\n",
       "       [[0.91978756],\n",
       "        [0.91502114],\n",
       "        [0.92094511],\n",
       "        ...,\n",
       "        [0.73253439],\n",
       "        [0.73423669],\n",
       "        [0.72831266]],\n",
       "\n",
       "       [[0.91502114],\n",
       "        [0.92094511],\n",
       "        [0.92087706],\n",
       "        ...,\n",
       "        [0.73423669],\n",
       "        [0.72831266],\n",
       "        [0.73396432]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22865314, 0.23055971, 0.22865314, ..., 0.72831266, 0.73396432,\n",
       "       0.73859458])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLLOWING SNIPPET ONLY GOOD FOR 1D/2D ARRAYS, AND NOY 3D ARRAYS\n",
    "\n",
    "# Series to DF, and then to csv\n",
    "#X_train = pd.DataFrame(X_train)\n",
    "#X_train.to_csv(\"X_train.csv\")\n",
    "\n",
    "# Numpy to csv\n",
    "#a = np.asarray(X_train)\n",
    "#np.savetxt(\"X_train.csv\", a, delimiter=\",\")\n",
    "\n",
    "# array to DF to csv\n",
    "# pd.DataFrame(X_train).to_csv(\"X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3267: FutureWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create an example array\n",
    "a = np.arange(24).reshape([2,3,4])\n",
    "\n",
    "# convert it to stacked format using Pandas\n",
    "stacked = pd.Panel(a.swapaxes(1,2)).to_frame().stack().reset_index()\n",
    "stacked.columns = ['x', 'y', 'z', 'value']\n",
    "\n",
    "# save to disk\n",
    "stacked.to_csv('stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2963: FutureWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Convert 3D arrays (X_train) to 'stacked' format using Pandas, and then to csv\n",
    "stacked = pd.Panel(X_train.swapaxes(1,2)).to_frame().stack().reset_index()\n",
    "stacked.columns = ['x', 'y', 'z', 'value']\n",
    "\n",
    "# save to disk\n",
    "stacked.to_csv('X_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array to DF to csv\n",
    "pd.DataFrame(y_train).to_csv(\"y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the RNN LSTM model\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "#Using TensorFlow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2709/2709 [==============================] - 19s 7ms/step - loss: 0.0164\n",
      "Epoch 2/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0034\n",
      "Epoch 3/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0032\n",
      "Epoch 4/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0029\n",
      "Epoch 5/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0029\n",
      "Epoch 6/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0025\n",
      "Epoch 7/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0025\n",
      "Epoch 8/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0023\n",
      "Epoch 9/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0021\n",
      "Epoch 10/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0021\n",
      "Epoch 11/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0021\n",
      "Epoch 12/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0023\n",
      "Epoch 13/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0019\n",
      "Epoch 14/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0018\n",
      "Epoch 17/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0018\n",
      "Epoch 18/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0016\n",
      "Epoch 19/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0017\n",
      "Epoch 20/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0016\n",
      "Epoch 21/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0014\n",
      "Epoch 22/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0014\n",
      "Epoch 23/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0013\n",
      "Epoch 24/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0014\n",
      "Epoch 25/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0014\n",
      "Epoch 26/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0014\n",
      "Epoch 27/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0013\n",
      "Epoch 28/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0013\n",
      "Epoch 29/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0012\n",
      "Epoch 30/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0012\n",
      "Epoch 31/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 0.0012\n",
      "Epoch 33/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0012\n",
      "Epoch 35/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 36/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 37/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 39/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0010\n",
      "Epoch 40/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0011\n",
      "Epoch 41/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.9660e-04\n",
      "Epoch 42/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0010\n",
      "Epoch 43/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 0.0010\n",
      "Epoch 44/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.9272e-04\n",
      "Epoch 45/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.8189e-04\n",
      "Epoch 46/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.3590e-04\n",
      "Epoch 47/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.3430e-04\n",
      "Epoch 48/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.9115e-04\n",
      "Epoch 49/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.1819e-04\n",
      "Epoch 50/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.0149e-04\n",
      "Epoch 51/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.7922e-04\n",
      "Epoch 52/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 8.6251e-04\n",
      "Epoch 53/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 9.1570e-04\n",
      "Epoch 54/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.5727e-04\n",
      "Epoch 55/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 8.7338e-04\n",
      "Epoch 56/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 8.0899e-04\n",
      "Epoch 57/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.2168e-04\n",
      "Epoch 58/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.2365e-04\n",
      "Epoch 59/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.6115e-04\n",
      "Epoch 60/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.1098e-04\n",
      "Epoch 61/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.7437e-04\n",
      "Epoch 62/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 8.6451e-04\n",
      "Epoch 63/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.6694e-04\n",
      "Epoch 64/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.2476e-04\n",
      "Epoch 65/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.5472e-04\n",
      "Epoch 66/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.1089e-04\n",
      "Epoch 67/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.1294e-04\n",
      "Epoch 68/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.4367e-04\n",
      "Epoch 69/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.0201e-04\n",
      "Epoch 70/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.6708e-04\n",
      "Epoch 71/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.4023e-04\n",
      "Epoch 72/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.5890e-04\n",
      "Epoch 73/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.8583e-04\n",
      "Epoch 74/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.7276e-04\n",
      "Epoch 75/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.2740e-04\n",
      "Epoch 76/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.9563e-04\n",
      "Epoch 77/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.2534e-04\n",
      "Epoch 78/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.4886e-04\n",
      "Epoch 79/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 8.4080e-04\n",
      "Epoch 80/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.9701e-04\n",
      "Epoch 81/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.6403e-04\n",
      "Epoch 82/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.4392e-04\n",
      "Epoch 83/100\n",
      "2709/2709 [==============================] - 16s 6ms/step - loss: 6.7959e-04\n",
      "Epoch 84/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.8721e-04\n",
      "Epoch 85/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.8375e-04\n",
      "Epoch 86/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 8.0305e-04\n",
      "Epoch 87/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.2423e-04\n",
      "Epoch 88/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.0776e-04\n",
      "Epoch 89/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.7725e-04\n",
      "Epoch 90/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.8610e-04\n",
      "Epoch 91/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 7.7645e-04\n",
      "Epoch 92/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.5797e-04\n",
      "Epoch 93/100\n",
      "2709/2709 [==============================] - 15s 6ms/step - loss: 6.4362e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 6.5871e-04\n",
      "Epoch 95/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 6.6918e-04\n",
      "Epoch 96/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.0876e-04\n",
      "Epoch 97/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 6.6272e-04\n",
      "Epoch 98/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.9049e-04\n",
      "Epoch 99/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 7.8166e-04\n",
      "Epoch 100/100\n",
      "2709/2709 [==============================] - 15s 5ms/step - loss: 6.6010e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2b9b7ef0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>41.919998</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>41.320000</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>1703300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>42.680000</td>\n",
       "      <td>41.939999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>1285600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.700001</td>\n",
       "      <td>42.160000</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>1389900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>42.380001</td>\n",
       "      <td>42.840000</td>\n",
       "      <td>42.240002</td>\n",
       "      <td>42.740002</td>\n",
       "      <td>1523300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>42.759998</td>\n",
       "      <td>42.919998</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>42.840000</td>\n",
       "      <td>2661900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open       high        low      close     volume\n",
       "date                                                             \n",
       "2007-01-03  41.919998  42.520000  41.320000  42.099998  1703300.0\n",
       "2007-01-04  42.000000  42.680000  41.939999  42.540001  1285600.0\n",
       "2007-01-05  42.599998  42.700001  42.160000  42.520000  1389900.0\n",
       "2007-01-08  42.380001  42.840000  42.240002  42.740002  1523300.0\n",
       "2007-01-09  42.759998  42.919998  42.500000  42.840000  2661900.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the real stock price of 2018\n",
    "dataset_test = pd.read_csv('expe_test.csv',index_col=\"date\",parse_dates=True)\n",
    "dataset_test = dataset_test.drop(columns = ['Unnamed: 0', 'adjusted'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2007-01-03    41.919998\n",
       "2007-01-04    42.000000\n",
       "2007-01-05    42.599998\n",
       "2007-01-08    42.380001\n",
       "2007-01-09    42.759998\n",
       "Name: open, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predicted stock price\n",
    "dataset_total = pd.concat((dataset['open'], dataset_test['open']), axis = 0)\n",
    "dataset_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (320,1) doesn't match the broadcast shape (320,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-796b91571aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_total\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    385\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (320,1) doesn't match the broadcast shape (320,5)"
     ]
    }
   ],
   "source": [
    "# Getting the real stock price of 2018\n",
    "dataset_test = pd.read_csv('expe_test.csv',index_col=\"date\",parse_dates=True)\n",
    "dataset_test = dataset_test.drop(columns = ['Unnamed: 0', 'adjusted'])\n",
    "dataset.head()\n",
    "\n",
    "# Getting the predicted stock price\n",
    "dataset_total = pd.concat((dataset['open'], dataset_test['open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Actual EXPE Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted EXPE Stock Price')\n",
    "plt.title('EXPE Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('EXPE Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
